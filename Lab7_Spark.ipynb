{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scalable Social Network Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation: Run ONCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "activate py35 && pip install sparkmagic==0.11.2 && pip install colorlover &&  jupyter nbextension enable --py --sys-prefix widgetsnbextension\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, load sparkmagic extention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext sparkmagic.magics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To connect to your HDInsight Spark cluster:\n",
    "* run \"%manage_spark\" to get the management panel\n",
    "* Add Endpoint: your cluster address (format: \"https://[myclustername].azurehdinsight.net/livy\") and your chosen user/password\n",
    "* Create Session: with language \"python\"\n",
    "* Wait until your session is ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%manage_spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Every spark cell has to start with %%spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "# First, we load the csv into an RDD named tweetsCSV\n",
    "tweetsCSV = sc.textFile(\"wasb://mie451datasets@mie451files.blob.core.windows.net/tweets2009-06-0115.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "# Print to validate tweetsCSV\n",
    "tweetsCSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "# \"take\" the first 5 items\n",
    "tweetsCSV.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "def isEnglish(s):\n",
    "    try:\n",
    "        s.encode('ascii')\n",
    "    except UnicodeEncodeError:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "# RDD Transformations: parse the data in tweetsCSV\n",
    "tweets = tweetsCSV.filter(lambda s: isEnglish(s)).map(lambda s: s.split(\"\\t\")).filter(lambda s: s[0] != \"date\" and len(s) == 3).map(lambda s:(str(s[0]), str(s[1]), str(s[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# Create schema for dataframe\n",
    "tweetsSchema = StructType([StructField(\"date\", StringType(), False), \n",
    "                           StructField(\"user\", StringType(), False), \n",
    "                           StructField(\"tweet\", StringType(), False)])\n",
    "\n",
    "# Create data frame\n",
    "tweetsDF = sqlContext.createDataFrame(tweets, tweetsSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "# Select-Where query (selecting all the tweets of use \"burtonator\")\n",
    "tweetsDF.where(tweetsDF.user==\"burtonator\").select(tweetsDF.date).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "# Register as a table to allow direct SQL queries\n",
    "tweetsDF.registerTempTable(\"tweets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use option \"-c sql\" to run sql queries on registered tables\n",
    "### Use option \"--maxrows X\" to limit the results to X records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark -c sql --maxrows 10\n",
    "SELECT * FROM tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use option \"-o dfname\" to save the results into a Pandas dataframe named dfname to allow further processing in the notebook (e.g., with networkx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark -c sql -o firstTen --maxrows 10\n",
    "SELECT * FROM tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstTen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to NetworkX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G.add_node(234)\n",
    "G.add_node(\"hello\")\n",
    "G.add_edge(234,\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Nodes:\", G.nodes())\n",
    "print(\"Edges:\", G.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G[234]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G['hello']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Properties on edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G.add_edge('Alice', 'Bob', {'know': 10, 'friends': 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Nodes:\", G.nodes())\n",
    "print(\"Edges:\", G.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G['Bob']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G['Alice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G['Bob']['Alice']['know'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G['Alice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G.add_edge('Alice', 'Carlos')\n",
    "G.add_edge('Carlos', 'Dave')\n",
    "G.add_edge('Dave', 'Bob')\n",
    "G.add_edge('Alice', 'Eve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = nx.connected_components(G)\n",
    "list(components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.degree(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.degree(G,'Bob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.has_path(G, 'Alice', 'Dave')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.has_path(G, 'Alice', 'hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.shortest_path(G, 'Alice', 'Dave')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.degree_centrality(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.betweenness_centrality(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Twitter Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding most common hash tags (RDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "import re\n",
    "wordTokenizerRegex = re.compile(\"[ ,.;]\")\n",
    "\n",
    "# Split to words and flatten using flatMap (to have one big RDD with all words). Then, we filter only hashtags (starting with \"#\")\n",
    "hashTags = tweets.flatMap(lambda s: wordTokenizerRegex.split(s[2])).filter(lambda w: w.startswith(\"#\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "# how many hashtags did we find\n",
    "print(hashTags.count())\n",
    "\n",
    "# examine the first 100\n",
    "print(hashTags.take(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "# count unique words and sort them in descending order of count\n",
    "countedHashTags = hashTags.map(lambda w: (w, 1)).reduceByKey(lambda a, b: a + b).sortBy(lambda tup: tup[1], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "#show top 100 words\n",
    "countedHashTags.take(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering tweets with selected hashtag #redsox (DataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use SQL queries to expore different tags and export the selected subset to a pandas dataframe (in the following case we choose \"redsox\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark -c sql --maxrows 10\n",
    "SELECT * FROM tweets WHERE LOWER(tweet) LIKE \"%#redsox%\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%spark -c sql -o onlyRedsox\n",
    "SELECT * FROM tweets WHERE LOWER(tweet) LIKE \"%#redsox%\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify pandas dataframe\n",
    "onlyRedsox.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTANT\n",
    "Once you've got the required dataframe - save it (to avoid having to re-run spark again next time):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "onlyRedsox.to_csv(\"backup-df-redsox.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTANT\n",
    "After you save your df you can always reload it, instead of re-creating it using spark.\n",
    "If you want to get the saved dataframe, just load it from disk as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "redsox = pd.DataFrame.from_csv(\"backup-df-redsox.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify loaded dataframe\n",
    "onlyRedsox.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we move to build the mention graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def addMentionedColumn(df):\n",
    "    \n",
    "    def mentionsList(txt):\n",
    "        allWords = [word.strip(\"\"\" ,.:'\\\";\"\"\").lower() for word in txt.split()]\n",
    "        allNames = [word.strip(\"@\") for word in allWords if word.startswith(\"@\")]\n",
    "        uniqueNames = list(set(allNames))\n",
    "        return allNames\n",
    "    \n",
    "    df[\"mentioned\"] = df[\"tweet\"].apply(mentionsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "addMentionedColumn(onlyRedsox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onlyRedsox.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mentionGraph(df):\n",
    "    g = nx.Graph()\n",
    "    \n",
    "    for (index, date, user, tweet, mentionedUsers) in df.itertuples():\n",
    "        for mentionedUser in mentionedUsers:\n",
    "            if (user in g) and (mentionedUser in g[user]):\n",
    "                g[user][mentionedUser][\"numberMentions\"] += 1\n",
    "            else:\n",
    "                g.add_edge(user, mentionedUser, {'numberMentions': 1})\n",
    "    \n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "redsoxGraph = mentionGraph(onlyRedsox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"# nodes:\", len(redsoxGraph.nodes()))\n",
    "print(\"# edges:\", len(redsoxGraph.edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redsoxGraph['shelley1005']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Mention Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "from plotly.graph_objs import *\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate random positions for nodes and store them at property \"pos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def addRandomPositions(graph):\n",
    "    posDict = dict((node,(random.gauss(0,10),random.gauss(0,10))) for node in graph.nodes())\n",
    "    nx.set_node_attributes(graph,\"pos\", posDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "addRandomPositions(redsoxGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.get_node_attributes(redsoxGraph, 'pos')['shelley1005']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize using Plot.ly scatter plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotNetwork(graph):\n",
    "    scatters=[]\n",
    "\n",
    "    for (node1, node2) in graph.edges():\n",
    "        x0, y0 = graph.node[node1]['pos']\n",
    "        x1, y1 = graph.node[node2]['pos']\n",
    "        edgeWidth = graph[node1][node2]['numberMentions']\n",
    "        s = Scatter(\n",
    "                x=[x0, x1],\n",
    "                y=[y0, y1],\n",
    "                hoverinfo='none',\n",
    "                mode='lines', \n",
    "                line=Line(width=1 ,color='#888'))\n",
    "        scatters.append(s)\n",
    "\n",
    "\n",
    "\n",
    "    for node in graph.nodes():\n",
    "        xPos, yPos = graph.node[node]['pos']\n",
    "        s = Scatter(\n",
    "                x=[xPos], \n",
    "                y=[yPos], \n",
    "                hoverinfo='none',\n",
    "                mode='marker', \n",
    "                marker=dict(\n",
    "                    color=\"#888\", \n",
    "                    size=10,         \n",
    "                    line=dict(width=2)))\n",
    "        scatters.append(s)\n",
    "    \n",
    "    layout = Layout(showlegend=False)\n",
    "    fig = Figure(data=scatters, layout=layout)\n",
    "    iplot(fig, show_link=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotNetwork(redsoxGraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize using node size and edge width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotNetworkSize(graph):\n",
    "    scatters=[]\n",
    "\n",
    "    for (node1, node2) in graph.edges():\n",
    "        x0, y0 = graph.node[node1]['pos']\n",
    "        x1, y1 = graph.node[node2]['pos']\n",
    "        edgeWidth = graph[node1][node2]['numberMentions']\n",
    "        s = Scatter(\n",
    "                x=[x0, x1],\n",
    "                y=[y0, y1],\n",
    "                hoverinfo='none',\n",
    "                mode='lines', \n",
    "                line=Line(width=edgeWidth ,color='#888'))\n",
    "        scatters.append(s)\n",
    "\n",
    "\n",
    "\n",
    "    for node in graph.nodes():\n",
    "        xPos, yPos = graph.node[node]['pos']\n",
    "        s = Scatter(\n",
    "                x=[xPos], \n",
    "                y=[yPos], \n",
    "                hoverinfo='none',\n",
    "                mode='marker', \n",
    "                marker=dict(\n",
    "                    color=\"#888\", \n",
    "                    size=nx.degree(graph,node)*2,         \n",
    "                    line=dict(width=2)))\n",
    "        scatters.append(s)\n",
    "    \n",
    "    layout = Layout(showlegend=False)\n",
    "    fig = Figure(data=scatters, layout=layout)\n",
    "    iplot(fig, show_link=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotNetworkSize(redsoxGraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using *Colorlover* for colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import colorlover as cl\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(cl.to_html( cl.scales['9'] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map purd color scale to 300 cells\n",
    "purd = cl.scales['9']['seq']['PuRd']\n",
    "purd300 = cl.interp(purd, 300)\n",
    "HTML(cl.to_html(purd300))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding color and text based on centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotNetworkSizeColor(graph):\n",
    "    closenessCentr = nx.closeness_centrality(redsoxGraph)\n",
    "    maxCentr = max(closenessCentr.values())\n",
    "    minCentr = min(closenessCentr.values())\n",
    "    \n",
    "    scatters=[]\n",
    "\n",
    "    for (node1, node2) in graph.edges():\n",
    "        x0, y0 = graph.node[node1]['pos']\n",
    "        x1, y1 = graph.node[node2]['pos']\n",
    "        edgeWidth = graph[node1][node2]['numberMentions']\n",
    "        s = Scatter(\n",
    "                x=[x0, x1],\n",
    "                y=[y0, y1],\n",
    "                hoverinfo='none',\n",
    "                mode='lines', \n",
    "                line=Line(width=edgeWidth ,color='#888'))\n",
    "        scatters.append(s)\n",
    "\n",
    "\n",
    "\n",
    "    for node in graph.nodes():\n",
    "        nodeCentr = closenessCentr[node]\n",
    "        nodeColor = int(299*(nodeCentr-minCentr)/(maxCentr-minCentr))\n",
    "        xPos, yPos = graph.node[node]['pos']\n",
    "        s = Scatter(\n",
    "                x=[xPos], \n",
    "                y=[yPos], \n",
    "                text=\"User: %s\\nCloseness: %.3f\" % (node, nodeCentr),\n",
    "                hoverinfo='text',\n",
    "                mode='marker', \n",
    "                marker=dict(\n",
    "                    color=purd300[nodeColor], \n",
    "                    size=nx.degree(graph,node)*2,         \n",
    "                    line=dict(width=2)))\n",
    "        scatters.append(s)\n",
    "    \n",
    "    layout = Layout(showlegend=False)\n",
    "    fig = Figure(data=scatters, layout=layout)\n",
    "    iplot(fig, show_link=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotNetworkSizeColor(redsoxGraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using NetworkX layouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def applyLayout(graph, layoutFunc):\n",
    "    posDict = layoutFunc(graph) \n",
    "    nx.set_node_attributes(graph, \"pos\", posDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spring layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redsoxGraphSpring = redsoxGraph.copy()\n",
    "applyLayout(redsoxGraphSpring, nx.spring_layout)\n",
    "plotNetworkSizeColor(redsoxGraphSpring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redsoxGraphRandom = redsoxGraph.copy()\n",
    "applyLayout(redsoxGraphRandom, nx.random_layout)\n",
    "plotNetworkSizeColor(redsoxGraphRandom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Circular layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redsoxGraphCircular = redsoxGraph.copy()\n",
    "applyLayout(redsoxGraphCircular, nx.circular_layout)\n",
    "plotNetworkSizeColor(redsoxGraphCircular)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redsoxGraphSpectral = redsoxGraph.copy()\n",
    "applyLayout(redsoxGraphSpectral, nx.spectral_layout)\n",
    "plotNetworkSizeColor(redsoxGraphSpectral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
