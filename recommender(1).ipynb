{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Recommender for MovieLens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting MovieLens data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Download the movielens 100k dataset from this link: [ml-100k.zip](http://files.grouplens.org/datasets/movielens/ml-100k.zip)\n",
    "\n",
    "* Upload ml-100k.zip\n",
    "\n",
    "* Extract using the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!unzip ml-100k.zip -d ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from heapq import nlargest\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define constant for movie lends 100K directory\n",
    "MOVIELENS_DIR = \"ml-100k/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we inspect the directory content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allbut.pl  u1.base  u2.test  u4.base  u5.test  ub.base\tu.genre  u.occupation\r\n",
      "mku.sh\t   u1.test  u3.base  u4.test  ua.base  ub.test\tu.info\t u.user\r\n",
      "README\t   u2.base  u3.test  u5.base  ua.test  u.data\tu.item\r\n"
     ]
    }
   ],
   "source": [
    "!ls $MOVIELENS_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then load the full MovieLens 100K dataset to find the number of users and items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  rating  timestamp\n",
       "0     196     242       3  881250949\n",
       "1     186     302       3  891717742\n",
       "2      22     377       1  878887116\n",
       "3     244      51       2  880606923\n",
       "4     166     346       1  886397596"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fields = ['userID', 'itemID', 'rating', 'timestamp']\n",
    "ratingDF = pd.read_csv(os.path.join(MOVIELENS_DIR, 'u.data'), sep='\\t', names=fields)\n",
    "\n",
    "ratingDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 943\n",
      "Number of items: 1682\n"
     ]
    }
   ],
   "source": [
    "numUsers = len(ratingDF.userID.unique())\n",
    "numItems = len(ratingDF.itemID.unique())\n",
    "\n",
    "print(\"Number of users:\", numUsers)\n",
    "print(\"Number of items:\", numItems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieID</th>\n",
       "      <th>movieTitle</th>\n",
       "      <th>releaseDate</th>\n",
       "      <th>videoReleaseDate</th>\n",
       "      <th>IMDbURL</th>\n",
       "      <th>unknown</th>\n",
       "      <th>action</th>\n",
       "      <th>adventure</th>\n",
       "      <th>animation</th>\n",
       "      <th>childrens</th>\n",
       "      <th>...</th>\n",
       "      <th>fantasy</th>\n",
       "      <th>filmNoir</th>\n",
       "      <th>horror</th>\n",
       "      <th>musical</th>\n",
       "      <th>mystery</th>\n",
       "      <th>romance</th>\n",
       "      <th>sciFi</th>\n",
       "      <th>thriller</th>\n",
       "      <th>war</th>\n",
       "      <th>western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Toy%20Story%2...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?GoldenEye%20(...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Four%20Rooms%...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Get%20Shorty%...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Copycat (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Copycat%20(1995)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieID         movieTitle  releaseDate  videoReleaseDate  \\\n",
       "0        1   Toy Story (1995)  01-Jan-1995               NaN   \n",
       "1        2   GoldenEye (1995)  01-Jan-1995               NaN   \n",
       "2        3  Four Rooms (1995)  01-Jan-1995               NaN   \n",
       "3        4  Get Shorty (1995)  01-Jan-1995               NaN   \n",
       "4        5     Copycat (1995)  01-Jan-1995               NaN   \n",
       "\n",
       "                                             IMDbURL  unknown  action  \\\n",
       "0  http://us.imdb.com/M/title-exact?Toy%20Story%2...        0       0   \n",
       "1  http://us.imdb.com/M/title-exact?GoldenEye%20(...        0       1   \n",
       "2  http://us.imdb.com/M/title-exact?Four%20Rooms%...        0       0   \n",
       "3  http://us.imdb.com/M/title-exact?Get%20Shorty%...        0       1   \n",
       "4  http://us.imdb.com/M/title-exact?Copycat%20(1995)        0       0   \n",
       "\n",
       "   adventure  animation  childrens   ...     fantasy  filmNoir  horror  \\\n",
       "0          0          1          1   ...           0         0       0   \n",
       "1          1          0          0   ...           0         0       0   \n",
       "2          0          0          0   ...           0         0       0   \n",
       "3          0          0          0   ...           0         0       0   \n",
       "4          0          0          0   ...           0         0       0   \n",
       "\n",
       "   musical  mystery  romance  sciFi  thriller  war  western  \n",
       "0        0        0        0      0         0    0        0  \n",
       "1        0        0        0      0         1    0        0  \n",
       "2        0        0        0      0         1    0        0  \n",
       "3        0        0        0      0         0    0        0  \n",
       "4        0        0        0      0         1    0        0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fieldsMovies = ['movieID', 'movieTitle', 'releaseDate', 'videoReleaseDate', 'IMDbURL', 'unknown', 'action', 'adventure',\n",
    "          'animation', 'childrens', 'comedy', 'crime', 'documentary', 'drama', 'fantasy', 'filmNoir', 'horror',\n",
    "          'musical', 'mystery', 'romance','sciFi', 'thriller', 'war', 'western']\n",
    "moviesDF = pd.read_csv(os.path.join(MOVIELENS_DIR, 'u.item'), sep='|', names=fieldsMovies, encoding='latin-1')\n",
    "\n",
    "moviesDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we load a train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of lines in train: 80000\n",
      "# of lines in test: 20000\n"
     ]
    }
   ],
   "source": [
    "trainDF = pd.read_csv(os.path.join(MOVIELENS_DIR, 'u1.base'), sep='\\t', names=fields)\n",
    "testDF = pd.read_csv(os.path.join(MOVIELENS_DIR, 'u1.test'), sep='\\t', names=fields)\n",
    "\n",
    "# test number of records (total should be 100K)\n",
    "print(\"# of lines in train:\", trainDF.shape[0])\n",
    "print(\"# of lines in test:\", testDF.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building User-to-Item Rating Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buildUserItemMatrix(dataset, numUsers, numItems):\n",
    "    # Initialize a of size (numUsers, numItems) to zeros\n",
    "    matrix = np.zeros((numUsers, numItems), dtype=np.int8)\n",
    "    \n",
    "    # Populate the matrix based on the dataset\n",
    "    for (index, userID, itemID, rating, timestamp) in dataset.itertuples():\n",
    "        matrix[userID-1, itemID-1] = rating\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainUserItemMatrix = buildUserItemMatrix(trainDF, numUsers, numItems)\n",
    "testUserItemMatrix = buildUserItemMatrix(testDF, numUsers, numItems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 3, 4, ..., 0, 0, 0],\n",
       "       [4, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [5, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 5, 0, ..., 0, 0, 0]], dtype=int8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the train matrix\n",
    "trainUserItemMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline solution - Average User Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predictByUserAverage(trainSet, numUsers, numItems):\n",
    "    # Initialize the predicted rating matrix with zeros\n",
    "    predictionMatrix = np.zeros((numUsers, numItems))\n",
    "    \n",
    "    for (user,item), rating in np.ndenumerate(trainSet):\n",
    "        # Predict rating for every item that wasn't ranked by the user (rating == 0)\n",
    "        if rating == 0:\n",
    "            # Extract the items the user already rated\n",
    "            userVector = trainSet[user, :]\n",
    "            ratedItems = userVector[userVector.nonzero()]\n",
    "            \n",
    "            # If not empty, calculate average and set as rating for the current item\n",
    "            if ratedItems.size == 0:\n",
    "                itemAvg = 0\n",
    "            else:\n",
    "                itemAvg = ratedItems.mean()\n",
    "            predictionMatrix[user, item] = itemAvg\n",
    "            \n",
    "        # report progress every 100 users\n",
    "        if (user % 100 == 0 and item == 1):\n",
    "            print (\"calculated %d users\" % (user,))\n",
    "    \n",
    "    return predictionMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    }
   ],
   "source": [
    "userAvgPreiction = predictByUserAverage(trainUserItemMatrix, numUsers, numItems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How well did we do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmse(pred, test):\n",
    "    # calculate RMSE for all the items in the test dataset\n",
    "    predItems = pred[test.nonzero()].flatten() \n",
    "    testItems = test[test.nonzero()].flatten()\n",
    "    return sqrt(mean_squared_error(predItems, testItems))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0629951276561334"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(userAvgPreiction, testUserItemMatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-User Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "userSimilarity = 1 - pairwise_distances(trainUserItemMatrix, metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predictByUserSimilarity(trainSet, numUsers, numItems, similarity):\n",
    "    # Initialize the predicted rating matrix with zeros\n",
    "    predictionMatrix = np.zeros((numUsers, numItems))\n",
    "    \n",
    "    for (user,item), rating in np.ndenumerate(trainSet):\n",
    "        # Predict rating for every item that wasn't ranked by the user (rating == 0)\n",
    "        if rating == 0:\n",
    "            # Extract the users that provided rating for this item\n",
    "            itemVector = trainSet[:,item]\n",
    "            usersRatings = itemVector[itemVector.nonzero()]\n",
    "            \n",
    "            # Get the similarity score for each of the users that provided rating for this item\n",
    "            usersSim = similarity[user,:][itemVector.nonzero()]\n",
    "            \n",
    "            # If there no users that ranked this item, use user's average\n",
    "            if len(usersSim) == 0:\n",
    "                userVector = trainSet[user, :]\n",
    "                ratedItems = userVector[userVector.nonzero()]\n",
    "                \n",
    "                # If the user didnt rated any item use 0, otherwise use average\n",
    "                if len(ratedItems) == 0:\n",
    "                    predictionMatrix[user,item] = 0\n",
    "                else:\n",
    "                    predictionMatrix[user,item] = ratedItems.mean()\n",
    "            else:\n",
    "                # predict score based on user-user similarity\n",
    "                predictionMatrix[user,item] = (usersRatings*usersSim).sum() / usersSim.sum()\n",
    "        if not np.isfinite(predictionMatrix[user,item]):\n",
    "            predictionMatrix[user,item]=0\n",
    "        \n",
    "        # report progress every 100 users\n",
    "        if (user % 100 == 0 and item == 1):\n",
    "            print (\"calculated %d users\" % (user,))\n",
    "    \n",
    "    return predictionMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/ipykernel/__main__.py:27: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    }
   ],
   "source": [
    "userSimPreiction = predictByUserSimilarity(trainUserItemMatrix, numUsers, numItems, userSimilarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.026449013124381"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(userSimPreiction, testUserItemMatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorized Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorizedUserSimRecSys(trainSet):\n",
    "    # Initialize the predicted rating matrix with zeros\n",
    "    temp_matrix = np.zeros(trainSet.shape)\n",
    "    temp_matrix[trainSet.nonzero()] = 1\n",
    "    uu_similarity = 1 - pairwise_distances(trainSet, metric='cosine')\n",
    "    normalizer = np.matmul(uu_similarity, temp_matrix)\n",
    "    normalizer[normalizer == 0] = 1e-5\n",
    "    predictionMatrix = np.matmul(uu_similarity, trainSet)/normalizer\n",
    "    #predictionMatrix[temp_matrix.nonzero()] = 0\n",
    "    #Cold start\n",
    "    \n",
    "    useraverage = np.sum(trainSet, axis=1)/np.sum(temp_matrix, axis=1)\n",
    "    columns = np.sum(predictionMatrix, axis=0)\n",
    "    predictionMatrix[:, columns==0] = predictionMatrix[:, columns==0] + np.expand_dims(useraverage, axis=1)\n",
    "    \n",
    "    return predictionMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "userSimPreiction = vectorizedUserSimRecSys(trainUserItemMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.026449013124381"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(userSimPreiction, testUserItemMatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision@k and Recall@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def avgPrecisionAtK(testSet, prediction, k):\n",
    "    # Initialize sum and count vars for average calculation\n",
    "    sumPrecisions = 0\n",
    "    countPrecisions = 0\n",
    "    \n",
    "    # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
    "    vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
    "    \n",
    "    for userID in range(numUsers):\n",
    "        # Pick top K based on predicted rating\n",
    "        userVector = prediction[userID,:]\n",
    "        topK = nlargest(k, range(len(userVector)), userVector.take)\n",
    "        \n",
    "        # Convert test set ratings to like / don't like\n",
    "        userTestVector = vf(testSet[userID,:]).nonzero()[0]\n",
    "        \n",
    "        # Calculate precision\n",
    "        precision = len([item for item in topK if item in userTestVector])/len(topK)\n",
    "        \n",
    "        # Update sum and count\n",
    "        sumPrecisions += precision\n",
    "        countPrecisions += 1\n",
    "        \n",
    "    # Return average P@k\n",
    "    return sumPrecisions/countPrecisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def avgRecallAtK(testSet, prediction, k):\n",
    "    # Initialize sum and count vars for average calculation\n",
    "    sumRecalls = 0\n",
    "    countRecalls = 0\n",
    "    \n",
    "    # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
    "    vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
    "    \n",
    "    for userID in range(numUsers):\n",
    "        # Pick top K based on predicted rating\n",
    "        userVector = prediction[userID,:]\n",
    "        topK = nlargest(k, range(len(userVector)), userVector.take)\n",
    "        \n",
    "        # Convert test set ratings to like / don't like\n",
    "        userTestVector = vf(testSet[userID,:]).nonzero()[0]\n",
    "        \n",
    "        # Ignore user if has no ratings in the test set\n",
    "        if (len(userTestVector) == 0):\n",
    "            continue\n",
    "        \n",
    "        # Calculate recall\n",
    "        recall = len([item for item in topK if item in userTestVector])/len(userTestVector)\n",
    "        \n",
    "        # Update sum and count\n",
    "        sumRecalls += recall\n",
    "        countRecalls += 1\n",
    "    \n",
    "    # Return average R@k\n",
    "    return sumRecalls/countRecalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k\tP@k\tR@k\n",
      "25\t0.016\t0.037\n",
      "50\t0.022\t0.101\n",
      "100\t0.022\t0.191\n",
      "250\t0.018\t0.368\n",
      "500\t0.016\t0.668\n"
     ]
    }
   ],
   "source": [
    "print(\"k\\tP@k\\tR@k\")\n",
    "for k in [25, 50, 100, 250, 500]:\n",
    "    print(\"%d\\t%.3lf\\t%.3lf\" % (k, avgPrecisionAtK(testUserItemMatrix, userSimPreiction, k), avgRecallAtK(testUserItemMatrix, userSimPreiction, k)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Popularity Based Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predictByPopularity(trainSet, numUsers, numItems):\n",
    "    # Initialize the predicted rating matrix with zeros\n",
    "    predictionMatrix = np.zeros((numUsers, numItems))\n",
    "    \n",
    "    # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
    "    vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
    "    \n",
    "    # For every item calculate the number of people liked (4-5) divided by the number of people that rated\n",
    "    itemPopularity = np.zeros((numItems))\n",
    "    for item in range(numItems):\n",
    "        numOfUsersRated = len(trainSet[:, item].nonzero()[0])\n",
    "        numOfUsersLiked = len(vf(trainSet[:, item]).nonzero()[0])\n",
    "        if numOfUsersRated == 0:\n",
    "            itemPopularity[item] = 0\n",
    "        else:\n",
    "            itemPopularity[item] = numOfUsersLiked/numOfUsersRated\n",
    "    \n",
    "    for (user,item), rating in np.ndenumerate(trainSet):\n",
    "        # Predict rating for every item that wasn't ranked by the user (rating == 0)\n",
    "        if rating == 0:\n",
    "            predictionMatrix[user, item] = itemPopularity[item]\n",
    "            \n",
    "        # report progress every 100 users\n",
    "        if (user % 100 == 0 and item == 1):\n",
    "            print (\"calculated %d users\" % (user,))\n",
    "    \n",
    "    return predictionMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    }
   ],
   "source": [
    "popPreiction = predictByPopularity(trainUserItemMatrix, numUsers, numItems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k\tP@k\tR@k\n",
      "25\t0.000\t0.000\n",
      "50\t0.004\t0.015\n",
      "100\t0.019\t0.155\n",
      "250\t0.021\t0.400\n",
      "500\t0.017\t0.688\n"
     ]
    }
   ],
   "source": [
    "print(\"k\\tP@k\\tR@k\")\n",
    "for k in [25, 50, 100, 250, 500]:\n",
    "    print(\"%d\\t%.3lf\\t%.3lf\" % (k, avgPrecisionAtK(testUserItemMatrix, popPreiction, k), avgRecallAtK(testUserItemMatrix, popPreiction, k)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Recommendations for a User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def userTopK(prediction, moviesDataset, userID, k):\n",
    "    # Pick top K based on predicted rating\n",
    "    userVector = prediction[userID+1,:]\n",
    "    topK = nlargest(k, range(len(userVector)), userVector.take)\n",
    "    namesTopK = list(map(lambda x: moviesDataset[moviesDataset.movieID == x+1][\"movieTitle\"].values[0], topK))\n",
    "    return namesTopK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Loch Ness (1995)',\n",
       " 'Perfect Candidate, A (1996)',\n",
       " 'Love and Death on Long Island (1997)',\n",
       " 'Crossfire (1947)',\n",
       " 'Celestial Clockwork (1994)',\n",
       " 'They Made Me a Criminal (1939)',\n",
       " 'Last Time I Saw Paris, The (1954)',\n",
       " 'Innocents, The (1961)',\n",
       " \"Jupiter's Wife (1994)\",\n",
       " 'Prefontaine (1997)']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recommend for userID 350 according to popularity recommender\n",
    "userTopK(popPreiction, moviesDF, 350, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Toy Story (1995)',\n",
       " 'GoldenEye (1995)',\n",
       " 'Four Rooms (1995)',\n",
       " 'Get Shorty (1995)',\n",
       " 'Copycat (1995)',\n",
       " 'Shanghai Triad (Yao a yao yao dao waipo qiao) (1995)',\n",
       " 'Twelve Monkeys (1995)',\n",
       " 'Babe (1995)',\n",
       " 'Dead Man Walking (1995)',\n",
       " 'Richard III (1995)']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recommend for userID 350 according to average rating recommender\n",
    "userTopK(userAvgPreiction, moviesDF, 350, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['They Made Me a Criminal (1939)',\n",
       " 'Prefontaine (1997)',\n",
       " 'Marlene Dietrich: Shadow and Light (1996) ',\n",
       " 'Star Kid (1997)',\n",
       " 'Santa with Muscles (1996)',\n",
       " \"Someone Else's America (1995)\",\n",
       " 'Entertaining Angels: The Dorothy Day Story (1996)',\n",
       " 'Saint of Fort Washington, The (1993)',\n",
       " 'Faust (1994)',\n",
       " 'Pather Panchali (1955)']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recommend for userID 350 according to user similarity recommender\n",
    "userTopK(userSimPreiction, moviesDF, 350, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the other datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datasetsFileNames = [('u2.base', 'u2.test'),\n",
    "                     ('u3.base', 'u3.test'),\n",
    "                     ('u4.base', 'u4.test'),\n",
    "                     ('u5.base', 'u5.test')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n",
      "calculated 0 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/ipykernel/__main__.py:27: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n",
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n",
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n",
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n",
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n",
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n",
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    }
   ],
   "source": [
    "rmseList = []\n",
    "for trainFileName, testFileName in datasetsFileNames:\n",
    "    curTrainDF = pd.read_csv(os.path.join(MOVIELENS_DIR, trainFileName), sep='\\t', names=fields)\n",
    "    curTestDF = pd.read_csv(os.path.join(MOVIELENS_DIR, testFileName), sep='\\t', names=fields)\n",
    "    curTrainUserItemMatrix = buildUserItemMatrix(curTrainDF, numUsers, numItems)\n",
    "    curTestUserItemMatrix = buildUserItemMatrix(curTestDF, numUsers, numItems)\n",
    "    \n",
    "    curUserAvgPreiction = predictByUserAverage(curTrainUserItemMatrix, numUsers, numItems)\n",
    "    avgRMSE = rmse(curUserAvgPreiction, curTestUserItemMatrix)\n",
    "    \n",
    "    curUserSimilarity = 1 - pairwise_distances(curTrainUserItemMatrix, metric='cosine')\n",
    "    curUserSimPreiction = predictByUserSimilarity(curTrainUserItemMatrix, numUsers, numItems, curUserSimilarity)\n",
    "    simRMSE = rmse(curUserSimPreiction, curTestUserItemMatrix)\n",
    "    \n",
    "    rmseList.append((avgRMSE, simRMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg\tSim\n",
      "1.047\t1.021\n",
      "1.033\t1.013\n",
      "1.037\t1.009\n",
      "1.039\t1.016\n"
     ]
    }
   ],
   "source": [
    "print(\"Avg\\tSim\")\n",
    "for avgScore, simScore in rmseList:\n",
    "    print(\"%.3lf\\t%.3lf\" % (avgScore, simScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
